{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vujanicr\\PycharmProjects\\nsopy-stoch\n"
     ]
    }
   ],
   "source": [
    "# Initial settings\n",
    "%cd ..\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison of Dual Methods\n",
    "\n",
    "## 1. Parameter Selection\n",
    "\n",
    "In this notebook we run the experiments necessary to determine good parameter settings for the different methods. We only consider the main parameter of each method\n",
    "* **Subgradient**: stepsize $p = s_0$\n",
    "* **Universal Gradient Methods**: optimality tolerance $p = \\epsilon$\n",
    "* **Quasi Monotone Methods**: $p = \\gamma$\n",
    "* **Cutting Planes/Bundle Methods**: optimality tolerance $p = \\epsilon$\n",
    "\n",
    "We select one representative instance of each model and test each method with parameter settings $p \\in \\left\\{ 0.1, 1, 10, 100 \\right\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# Experiment Settings #\n",
    "#######################\n",
    "\n",
    "# 1) Do restricted number of tests?\n",
    "# if True, only run tests for one method (TA 2)\n",
    "process_only_one_solution_method = True\n",
    "# if True, only test one instance class (sslp)\n",
    "process_only_one_class = True\n",
    "\n",
    "# 2) Output files names\n",
    "filename_parameter_scan_record = 'ZZ_parameter_scan_record.csv'\n",
    "filename_parameter_selection = 'ZZ_parameter_selection.csv'\n",
    "\n",
    "# 3) Max time (approx) for single run in minutes\n",
    "single_experiment_timeout = 0.1  # for the paper we set this to 30 [minutes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nsopy import DualMethodsFactory, AVAILABLE_METHODS\n",
    "from nsopy import EnhancedDualMethodLogger, SlimDualMethodLogger\n",
    "from nsopy.methods.utils import record_logger\n",
    "from itertools import product\n",
    "\n",
    "# Determine EXPERIMENT tuples ('method', parameter)\n",
    "PARAMETERS = (0.01, 0.1, 1.0, 10.0, 100.0)\n",
    "if process_only_one_solution_method:\n",
    "    AVAILABLE_METHODS = ('TA 2',)  # to test only one method\n",
    "experiments = product(AVAILABLE_METHODS, PARAMETERS)  # iterable\n",
    "experiments = [exp for exp in experiments]  # make flat list because we want to iterate over it many times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pick thet first instance of each problem type as a representative\n",
    "\n",
    "##### Important: the code has been changed so that only the problem set tested is `SSLP`. Uncomment box to run everything. `SSLP` only takes about an hour on a normal PC; all instances will take 4-6 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing nominal model information from smps/benchmark_problems/2_sslp/sslp_5_25_3_mymod.cor and .tim ...\n",
      "Parsing stochastic information from smps/benchmark_problems/2_sslp/sslp_5_25_3_mymod.sto ...\n",
      "Stochastic model is of type SCENARIOS DISCRETE\n"
     ]
    }
   ],
   "source": [
    "from smps.inner_problems_factory import BenchmarkInnerProblemsFactory, STOCH_INSTANCES\n",
    "\n",
    "# run only one class\n",
    "if process_only_one_class:\n",
    "    inner_problems = []\n",
    "    for subtype in STOCH_INSTANCES:\n",
    "        if subtype == 'sslp':\n",
    "            inner_problems.append(BenchmarkInnerProblemsFactory(type='2 stage stoch', subtype=subtype, instance_n=0))\n",
    "\n",
    "# run all tests\n",
    "elif not process_only_one_class:\n",
    "    inner_problems = []\n",
    "    for subtype in STOCH_INSTANCES:\n",
    "        if subtype != 'all':\n",
    "            inner_problems.append(BenchmarkInnerProblemsFactory(type='2 stage stoch', subtype=subtype, instance_n=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods = [[DualMethodsFactory(ip, method=exp[0], param=exp[1]) for exp in experiments] for ip in inner_problems]\n",
    "loggers = [[SlimDualMethodLogger(method) for method in ip] for ip in methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting appropriate dual domain for bundle and cutting planes methods\n",
    "for ip in methods:\n",
    "    for method in ip:\n",
    "        if 'Cutting' in method.desc or 'Bundle' in method.desc:\n",
    "            method.set_dual_domain(type='2 stage smps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the experiments. Method loggers are objects that store the results from each run; the conent of these loggers is then saved into csv files by calling `record_logger()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nsopy.methods.quasi_monotone_subgradient_methods.SGMTripleAveraging object at 0x000000000478A710>\n",
      "oracle_time  = 0.077999830246, N_ORACLE_CALLS = 76.9232443337\n",
      "File ZZ_parameter_scan_record.csv does not exist\n",
      "Record file does not exist. Creating ZZ_parameter_scan_record.csv ...\n",
      "<nsopy.methods.quasi_monotone_subgradient_methods.SGMTripleAveraging object at 0x000000000931EC50>\n",
      "oracle_time  = 0.0550000667572, N_ORACLE_CALLS = 109.09077668\n",
      "<nsopy.methods.quasi_monotone_subgradient_methods.SGMTripleAveraging object at 0x000000000931ECF8>\n",
      "oracle_time  = 0.0599999427795, N_ORACLE_CALLS = 100.000095368\n",
      "<nsopy.methods.quasi_monotone_subgradient_methods.SGMTripleAveraging object at 0x000000000931ED68>\n",
      "oracle_time  = 0.0540001392365, N_ORACLE_CALLS = 111.110824617\n",
      "<nsopy.methods.quasi_monotone_subgradient_methods.SGMTripleAveraging object at 0x000000000931EDD8>\n",
      "oracle_time  = 0.106000185013, N_ORACLE_CALLS = 56.6036747886\n"
     ]
    }
   ],
   "source": [
    "for index_ip, ip in enumerate(methods):\n",
    "    for index_method, method in enumerate(ip):\n",
    "        print method\n",
    "        \n",
    "        # Determine N_ORACLE_CALLS allocated for experiment\n",
    "        start_time = time.time()\n",
    "        method.oracle(method.projection_function(np.zeros(method.dimension, dtype=float)))\n",
    "        oracle_time = time.time() - start_time\n",
    "\n",
    "        # Set value\n",
    "        N_ORACLE_CALLS = min(1000,  single_experiment_timeout*float(60)/oracle_time)\n",
    "        print 'oracle_time  = {}, N_ORACLE_CALLS = {}'.format(oracle_time, N_ORACLE_CALLS)\n",
    "        \n",
    "        i = 0\n",
    "        while method.oracle_calls < N_ORACLE_CALLS and i < N_ORACLE_CALLS:\n",
    "            method.dual_step()\n",
    "            i += 1  # we have to add this because cutting planes stop querying oracles when they find the solution\n",
    "        \n",
    "        record_logger(loggers[index_ip][index_method], filename=filename_parameter_scan_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are logged in the file `parameter_scan_record.csv`. We determine now the best parameter for each method for each class of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in file and prepare extra columns\n",
    "results = pd.read_csv(filename_parameter_scan_record)\n",
    "# add new columns\n",
    "results['d_k_max'] = None\n",
    "results['iteration of d_k_max'] = None\n",
    "results['is_competitive'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine \"winning\" parameter, store it in `parameter_selection` (dataframe) and write results in `parameter_selection.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nsopy.methods.utils import flatten_record_dataframe\n",
    "\n",
    "results = flatten_record_dataframe(results)\n",
    "parameter_selection = pd.DataFrame(columns=('subtype', 'method_name', 'selected_parameter'))\n",
    "\n",
    "for subtype in results['instance_subtype'].unique():\n",
    "    for method_name in results['method_name'].unique():        \n",
    "        # First pass: find minimum, and competitive parameters (i.e., within 1%) and iteration of minimum\n",
    "        maxima = []\n",
    "        maxima_iteration = []\n",
    "        for index, result in results[(results['instance_subtype']==subtype) & (results['method_name']==method_name)].iterrows():\n",
    "            results.set_value(index, 'd_k_max', max(result.d_k))\n",
    "            maxima.append(max(result.d_k))\n",
    "            results.set_value(index, 'iteration of d_k_max', result.oracle_calls[np.argmax(result.d_k)])\n",
    "            maxima_iteration.append(np.argmax(result.d_k))\n",
    "\n",
    "        # Then search for the \"winner\" parameter\n",
    "        winner_iterations = np.infty\n",
    "        for index, result in results[(results['instance_subtype']==subtype) & (results['method_name']==method_name)].iterrows():\n",
    "            if (abs(result.d_k_max - max(maxima)) < 0.001*abs(max(maxima))) and (result['iteration of d_k_max'] <= winner_iterations):\n",
    "                winner_parameter = result.method_parameter\n",
    "                winner_iterations = result['iteration of d_k_max']\n",
    "        \n",
    "        parameter_selection.loc[len(parameter_selection)] = subtype, method_name, winner_parameter\n",
    "\n",
    "parameter_selection.to_csv(filename_parameter_selection, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtype</th>\n",
       "      <th>method_name</th>\n",
       "      <th>selected_parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sslp</td>\n",
       "      <td>TA 2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subtype method_name  selected_parameter\n",
       "0    sslp        TA 2                0.01"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}